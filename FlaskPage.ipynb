{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlaskPage.ipynb",
      "provenance": [],
      "mount_file_id": "1RikLI6pHpoovrTO6q_dAzAULGfJDkKe0",
      "authorship_tag": "ABX9TyPdWW7RTUSzhxEb8EHoe/TS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/js0807/ai_study/blob/main/FlaskPage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNmmOCue_loL"
      },
      "source": [
        "# Flask 기초"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFjAoINj9BJf",
        "outputId": "4f9731ef-f07e-415e-c7e2-0d4571997e46"
      },
      "source": [
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return \"<h1>This is your Flask server.</h1>\"\n",
        "\n",
        "@app.route(\"/predict\")\n",
        "def predict():\n",
        "  message=\"\"\n",
        "  message+=\"<h1>House Prices</h1>\"\n",
        "  message+=\"This page will be your prediction form.\"\n",
        "\n",
        "  return message\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://edddf4ecf6ef.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Aug/2021 12:06:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Aug/2021 12:06:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [09/Aug/2021 12:06:50] \"\u001b[37mGET /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0clRedjc_ruY"
      },
      "source": [
        "# 실전"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2OnF0Km-44p"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43MVJwSx779j",
        "outputId": "e1a16c4d-c65c-441b-ffc0-0bccafb9b10c"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdtMFkJa-3D0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQo91yov_Djg"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCRuYrdS_IN4",
        "outputId": "15c153a5-7949-4a89-ba4d-d4870de62227"
      },
      "source": [
        "cd /content/drive/MyDrive/data/house_prices/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data/house_prices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwjyq0rg_Fgg"
      },
      "source": [
        "# load data\n",
        "X = pd.read_csv('X.csv')\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "    y = np.load(f)\n",
        "\n",
        "# OverallQual 10\n",
        "# GrLivArea 10\n",
        "# GarageCars 9\n",
        "# GarageArea 8\n",
        "# TotalBsmtSF 7\n",
        "# 1stFlrSF 6\n",
        "# FullBath 5\n",
        "# LotShape Reg\n",
        "X = X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "scaled_y = y_min_max_scaler.transform(y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab09ALft_Ryb"
      },
      "source": [
        "## Training & Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTlb-EbL_TIO",
        "outputId": "962e1572-1145-4351-906b-dd1030d602b2"
      },
      "source": [
        "model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=scaled_X.shape[-1]),\n",
        "          layers.Dense(96, activation='relu'),\n",
        "          layers.Dense(48, activation='relu'),\n",
        "          layers.Dense(1)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "model.fit(scaled_X, scaled_y, \n",
        "          batch_size=2, epochs=150, \n",
        "          callbacks=[early_stopping_callback], validation_split=0.05)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Epoch 1/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0040 - val_loss: 0.0018\n",
            "Epoch 2/150\n",
            "694/694 [==============================] - 1s 1000us/step - loss: 0.0034 - val_loss: 0.0032\n",
            "Epoch 3/150\n",
            "694/694 [==============================] - 1s 984us/step - loss: 0.0032 - val_loss: 0.0018\n",
            "Epoch 4/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
            "Epoch 5/150\n",
            "694/694 [==============================] - 1s 987us/step - loss: 0.0027 - val_loss: 0.0016\n",
            "Epoch 6/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 7/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 8/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0013\n",
            "Epoch 9/150\n",
            "694/694 [==============================] - 1s 983us/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 10/150\n",
            "694/694 [==============================] - 1s 986us/step - loss: 0.0026 - val_loss: 0.0031\n",
            "Epoch 11/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 12/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 13/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 14/150\n",
            "694/694 [==============================] - 1s 980us/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 15/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0038\n",
            "Epoch 16/150\n",
            "694/694 [==============================] - 1s 982us/step - loss: 0.0023 - val_loss: 0.0024\n",
            "Epoch 17/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0014\n",
            "Epoch 18/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 19/150\n",
            "694/694 [==============================] - 1s 983us/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 20/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 21/150\n",
            "694/694 [==============================] - 1s 975us/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 22/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0014\n",
            "Epoch 23/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0929801910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwAImV8iGDRq",
        "outputId": "71772bd3-709c-482b-871c-02e6d785eaa5"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/data/house_prices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXIrARyDCwjm"
      },
      "source": [
        "model.save(\"mlp_v0.1.h5\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu1Nb6NGCx6i"
      },
      "source": [
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3zWeVEn_UB9"
      },
      "source": [
        "# with no saved model\n",
        "# pred = model.predict(scaled_X[:5]) # 0 ~ 1\n",
        "# pred = y_min_max_scaler.inverse_transform(pred)\n",
        "\n",
        "# with saved model\n",
        "pred = reconstructed_model.predict(scaled_X[:1]) # 0 ~ 1\n",
        "pred = y_min_max_scaler.inverse_transform(pred)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnRE56jW_-jm"
      },
      "source": [
        "## to Flask Page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5d1onz7CkEV"
      },
      "source": [
        "template_folder_pwd='/content/drive/MyDrive/data/deployment/'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKEuqccU9YDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2230367-02ab-4a6b-c339-0ad817453566"
      },
      "source": [
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# load data\n",
        "X = pd.read_csv('X.csv')\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "    y = np.load(f)\n",
        "\n",
        "X = X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "\n",
        "# load model\n",
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")\n",
        "\n",
        "app=Flask(__name__,template_folder=template_folder_pwd)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "def preprocess_data(data):\n",
        "  X = [] # <-- OverallQual, GrLivArea, ... LotShape\n",
        "  for k, v in data.items():\n",
        "    if k == 'LotShape':\n",
        "      if v == 'Reg':\n",
        "        X.append(4)\n",
        "      elif v == 'IR1':\n",
        "        X.append(3)\n",
        "      elif v == 'IR2':\n",
        "        X.append(2)\n",
        "      else:\n",
        "        X.append(1)\n",
        "    else:\n",
        "      X.append(float(v))\n",
        "\n",
        "  # X = [2, 5000, 2, ... , 3]\n",
        "  X = np.array(X) # (8,)\n",
        "  X = X.reshape((1, -1)) # (1, 8)\n",
        "\n",
        "  # min max scaling\n",
        "  scaled_X = x_min_max_scaler.transform(X)\n",
        "  print(scaled_X)\n",
        "\n",
        "  return scaled_X\n",
        "\n",
        "@app.route(\"/\")\n",
        "def predict():\n",
        "  return render_template('submit_form.html')\n",
        "\n",
        "@app.route(\"/result\",methods=['POST'])\n",
        "def result():\n",
        "\n",
        "  data=request.form\n",
        "\n",
        "  message=\"\"\n",
        "  message+=\"<h1>House Prices</h1>\"\n",
        "\n",
        "  for k,v in data.items():\n",
        "    message+=k+\": \"+v+\"</br>\"\n",
        "\n",
        "  X=preprocess_data(data)\n",
        "\n",
        "  pred = reconstructed_model.predict(X)\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "\n",
        "  message+=\"<br><hr><br>\"\n",
        "  message+=\"Your House SalePrice is...\"\n",
        "  message+=\"<br>\"\n",
        "  message+=\"<h1 style='color:ForestGreen;'>$ \"+str(pred[0][0])+\" $</h1>\"\n",
        "\n",
        "  return message\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://4f0fb1d7e976.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Aug/2021 13:32:00] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Aug/2021 13:32:00] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.55555556 0.21288621 0.5        0.33850494 0.16219313 0.17278568\n",
            "  0.66666667 0.66666667]]\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f092977d710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Aug/2021 13:32:02] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [09/Aug/2021 13:32:08] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.55555556 0.21288621 0.5        0.33850494 0.16219313 0.17278568\n",
            "  0.         1.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Aug/2021 13:32:11] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.55555556 0.21288621 0.5        0.33850494 0.16219313 0.17278568\n",
            "  0.         0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Aug/2021 13:32:17] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.55555556 0.21288621 0.5        0.33850494 0.16219313 0.17278568\n",
            "  0.66666667 0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [09/Aug/2021 13:32:22] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0.55555556 0.21288621 0.5        0.33850494 0.16219313 0.17278568\n",
            "  1.66666667 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbjgjfzcKzEB"
      },
      "source": [
        "# +α\n",
        "* deployment 진행 시 꼭! import 해야하는 package들의 version을 알아두고, 그거에 맞게 다운로드 진행하자!\n",
        "    * !pip list | grep tensorflow, pandas, keras, ...\n",
        "    * 이 것들을 편하게 설치하기 위해 requirements.txt에 각 패키지 및 버전 저장\n",
        "        * ex) tensorflow==2.5.0\n",
        "    * 그 후 pip install -r requirements.txt\n",
        "* 서버에서 계속 돌려야 하는 경우. 백그라운드로 서버를 계속 돌려야한다.\n",
        "    * nohub python3 flask-app.py &\n",
        "    * 그러면 nohup.out 이라고 로그 남음\n",
        "    * tail -f nohup.out # 계속 로그보기\n"
      ]
    }
  ]
}